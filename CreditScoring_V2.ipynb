{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('kredit.csv')\n",
    "X = dataset[['laufkont','laufzeit','sparkont','moral']]\n",
    "y = dataset['kredit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     laufkont  laufzeit  sparkont  moral\n",
      "253         4        36         1      2\n",
      "667         2        13         1      4\n",
      "85          1        12         4      2\n",
      "969         1        21         5      1\n",
      "75          2         9         5      2\n",
      "..        ...       ...       ...    ...\n",
      "835         2        24         1      2\n",
      "192         2        48         5      2\n",
      "629         1        12         1      2\n",
      "559         2        14         3      2\n",
      "684         1        12         1      2\n",
      "\n",
      "[750 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253    1\n",
      "667    1\n",
      "85     1\n",
      "969    0\n",
      "75     1\n",
      "      ..\n",
      "835    0\n",
      "192    1\n",
      "629    1\n",
      "559    1\n",
      "684    1\n",
      "Name: kredit, Length: 750, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     laufkont  laufzeit  sparkont  moral\n",
      "993         1        18         1      4\n",
      "859         1        12         2      2\n",
      "298         2        12         4      2\n",
      "553         4        10         5      2\n",
      "672         2        18         1      2\n",
      "..        ...       ...       ...    ...\n",
      "462         4        15         2      2\n",
      "356         1        24         1      2\n",
      "2           2        12         2      2\n",
      "478         4        12         1      4\n",
      "695         4        60         1      3\n",
      "\n",
      "[250 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993    0\n",
      "859    0\n",
      "298    1\n",
      "553    1\n",
      "672    1\n",
      "      ..\n",
      "462    1\n",
      "356    1\n",
      "2      1\n",
      "478    1\n",
      "695    1\n",
      "Name: kredit, Length: 250, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scalling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually in LR it doesn't needs feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.14276934  1.23662853 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.64282893 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.72454447  1.20674409 -0.54268053]\n",
      " ...\n",
      " [-1.24020657 -0.72454447 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.56111338  0.57294993 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -0.54268053]]\n"
     ]
    }
   ],
   "source": [
    "#print features in same range, transform features in same range\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.24020657 -0.23425122 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.72454447 -0.06084424 -0.54268053]\n",
      " [-0.44588127 -0.72454447  1.20674409 -0.54268053]\n",
      " [ 1.14276934 -0.88797555  1.84053826 -0.54268053]\n",
      " [-0.44588127 -0.23425122 -0.69463841 -0.54268053]\n",
      " [-0.44588127  0.50118865 -0.69463841 -2.41399271]\n",
      " [-0.44588127 -0.96969109 -0.69463841  1.32863165]\n",
      " [ 1.14276934 -1.21483771 -0.69463841 -2.41399271]\n",
      " [-1.24020657 -1.21483771 -0.69463841 -0.54268053]\n",
      " [ 0.34844403  0.25604203  1.84053826  1.32863165]\n",
      " [ 1.14276934 -1.21483771 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203  1.84053826 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -1.47833662]\n",
      " [ 1.14276934  1.48177515  0.57294993 -0.54268053]\n",
      " [-1.24020657  0.9914819   0.57294993  1.32863165]\n",
      " [-1.24020657 -0.72454447 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.23425122 -0.69463841 -1.47833662]\n",
      " [ 1.14276934  0.25604203  0.57294993 -0.54268053]\n",
      " [-1.24020657 -0.23425122  1.84053826 -0.54268053]\n",
      " [ 1.14276934  0.25604203  1.20674409  1.32863165]\n",
      " [ 1.14276934  1.23662853 -0.69463841  1.32863165]\n",
      " [-0.44588127 -0.23425122 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.72454447  1.84053826  1.32863165]\n",
      " [ 1.14276934  2.21721502  1.84053826  1.32863165]\n",
      " [-0.44588127 -0.47939784 -0.06084424 -1.47833662]\n",
      " [-0.44588127  0.25604203 -0.69463841 -2.41399271]\n",
      " [-1.24020657 -0.23425122 -0.69463841 -0.54268053]\n",
      " [-0.44588127  1.23662853 -0.69463841  0.39297556]\n",
      " [-0.44588127  2.21721502 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.96969109 -0.69463841  1.32863165]\n",
      " [-1.24020657  0.01089541 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203 -0.69463841 -0.54268053]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.47939784 -0.69463841 -2.41399271]\n",
      " [-0.44588127 -0.23425122  1.20674409 -0.54268053]\n",
      " [-0.44588127 -0.96969109 -0.69463841 -0.54268053]\n",
      " [-0.44588127  0.74633528 -0.06084424 -0.54268053]\n",
      " [ 0.34844403  0.25604203  0.57294993 -0.54268053]\n",
      " [-1.24020657  2.21721502 -0.69463841 -2.41399271]\n",
      " [ 1.14276934  1.23662853  0.57294993 -0.54268053]\n",
      " [ 1.14276934  0.25604203 -0.69463841 -0.54268053]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [-0.44588127  1.9720684  -0.06084424  1.32863165]\n",
      " [-0.44588127 -0.23425122 -0.69463841  0.39297556]\n",
      " [-0.44588127 -1.21483771  1.20674409 -1.47833662]\n",
      " [ 1.14276934 -0.96969109 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.96969109  1.84053826 -0.54268053]\n",
      " [ 1.14276934  0.25604203 -0.69463841 -1.47833662]\n",
      " [-1.24020657  1.23662853 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.23425122 -0.69463841  1.32863165]\n",
      " [ 1.14276934  1.23662853 -0.69463841 -0.54268053]\n",
      " [ 0.34844403 -0.88797555 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.47939784  0.57294993  1.32863165]\n",
      " [-0.44588127 -0.72454447 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203 -0.06084424 -0.54268053]\n",
      " [ 1.14276934 -1.21483771  0.57294993 -0.54268053]\n",
      " [ 1.14276934 -1.21483771  0.57294993 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.06084424 -0.54268053]\n",
      " [ 1.14276934 -1.21483771 -0.06084424 -2.41399271]\n",
      " [ 1.14276934  2.21721502  1.84053826 -0.54268053]\n",
      " [-1.24020657  2.21721502 -0.69463841  1.32863165]\n",
      " [-0.44588127  0.25604203  1.84053826 -0.54268053]\n",
      " [ 0.34844403 -0.23425122  1.84053826 -1.47833662]\n",
      " [ 1.14276934  0.25604203  0.57294993  0.39297556]\n",
      " [ 1.14276934 -1.21483771 -0.69463841  1.32863165]\n",
      " [ 1.14276934 -0.72454447 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203  1.84053826  1.32863165]\n",
      " [ 1.14276934 -0.72454447 -0.69463841 -0.54268053]\n",
      " [-1.24020657  1.23662853 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.47939784 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.23425122 -0.69463841  0.39297556]\n",
      " [ 1.14276934 -0.72454447 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203 -0.06084424  0.39297556]\n",
      " [-1.24020657  0.25604203 -0.69463841 -1.47833662]\n",
      " [ 1.14276934 -0.72454447  1.84053826  1.32863165]\n",
      " [-1.24020657  0.25604203  1.84053826 -0.54268053]\n",
      " [ 0.34844403 -0.23425122 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203 -0.69463841  1.32863165]\n",
      " [-0.44588127  2.21721502  1.84053826  0.39297556]\n",
      " [ 1.14276934 -0.80626001 -0.69463841  1.32863165]\n",
      " [-0.44588127 -0.07082014 -0.69463841  0.39297556]\n",
      " [-0.44588127 -0.96969109 -0.69463841 -0.54268053]\n",
      " [-0.44588127  2.21721502 -0.69463841  1.32863165]\n",
      " [-1.24020657  2.21721502 -0.69463841 -2.41399271]\n",
      " [ 1.14276934 -0.47939784 -0.69463841  0.39297556]\n",
      " [ 1.14276934  0.01089541 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203 -0.06084424  1.32863165]\n",
      " [ 1.14276934  0.25604203  1.84053826  1.32863165]\n",
      " [-0.44588127  0.25604203 -0.69463841 -1.47833662]\n",
      " [-0.44588127 -0.88797555 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841  1.32863165]\n",
      " [-1.24020657  0.50118865 -0.69463841 -2.41399271]\n",
      " [ 0.34844403 -0.96969109 -0.06084424 -0.54268053]\n",
      " [-1.24020657 -0.07082014 -0.69463841  1.32863165]\n",
      " [ 1.14276934 -0.72454447 -0.69463841  1.32863165]\n",
      " [ 1.14276934 -0.72454447 -0.69463841  1.32863165]\n",
      " [ 1.14276934  0.25604203 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.72454447 -0.69463841 -2.41399271]\n",
      " [ 1.14276934  0.25604203 -0.69463841  1.32863165]\n",
      " [ 1.14276934  0.25604203  0.57294993 -0.54268053]\n",
      " [ 1.14276934  1.23662853 -0.69463841  0.39297556]\n",
      " [ 1.14276934 -1.21483771 -0.06084424  1.32863165]\n",
      " [-0.44588127  1.23662853 -0.69463841  0.39297556]\n",
      " [ 0.34844403 -0.72454447 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841  1.32863165]\n",
      " [-0.44588127 -1.13312217 -0.69463841 -0.54268053]\n",
      " [-0.44588127  0.25604203 -0.69463841  1.32863165]\n",
      " [-0.44588127  0.74633528 -0.06084424 -2.41399271]\n",
      " [-0.44588127 -0.96969109  1.84053826 -0.54268053]\n",
      " [-0.44588127  1.23662853 -0.69463841  0.39297556]\n",
      " [-1.24020657 -0.72454447 -0.06084424 -0.54268053]\n",
      " [-0.44588127 -0.72454447  1.84053826 -0.54268053]\n",
      " [ 1.14276934 -0.23425122  1.84053826 -0.54268053]\n",
      " [ 0.34844403 -0.47939784 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.96969109 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -1.05140663 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  3.19780152  1.84053826  1.32863165]\n",
      " [ 1.14276934 -0.72454447  1.84053826 -0.54268053]\n",
      " [-0.44588127  0.74633528 -0.69463841 -0.54268053]\n",
      " [-0.44588127  0.74633528 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.23425122 -0.69463841 -2.41399271]\n",
      " [-0.44588127 -1.21483771 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.88797555 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.72454447  0.57294993  1.32863165]\n",
      " [-0.44588127  0.25604203 -0.69463841  1.32863165]\n",
      " [-0.44588127  0.25604203  1.20674409  1.32863165]\n",
      " [-0.44588127  0.01089541 -0.69463841  0.39297556]\n",
      " [-0.44588127  1.23662853 -0.06084424  0.39297556]\n",
      " [-1.24020657  2.21721502 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203 -0.06084424 -0.54268053]\n",
      " [-1.24020657 -0.47939784 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.96969109  1.84053826  1.32863165]\n",
      " [-0.44588127  0.25604203  0.57294993 -0.54268053]\n",
      " [-1.24020657  0.25604203 -0.69463841  1.32863165]\n",
      " [ 1.14276934 -1.21483771  1.20674409  1.32863165]\n",
      " [ 1.14276934 -0.23425122 -0.69463841  1.32863165]\n",
      " [ 1.14276934 -0.23425122 -0.69463841  1.32863165]\n",
      " [-0.44588127  0.74633528 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.47939784 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  1.23662853 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.01089541  1.84053826 -0.54268053]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.47939784 -0.69463841  1.32863165]\n",
      " [ 1.14276934  1.72692177  0.57294993  1.32863165]\n",
      " [-0.44588127 -0.96969109 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203  1.84053826 -0.54268053]\n",
      " [-1.24020657 -0.47939784 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  1.23662853  0.57294993  0.39297556]\n",
      " [ 0.34844403  0.74633528 -0.69463841  1.32863165]\n",
      " [ 1.14276934  0.25604203 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -2.41399271]\n",
      " [-1.24020657  0.74633528 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.23425122 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.23425122  1.20674409 -0.54268053]\n",
      " [ 1.14276934 -1.21483771  1.84053826  1.32863165]\n",
      " [ 1.14276934  2.21721502  1.84053826 -0.54268053]\n",
      " [ 1.14276934 -0.72454447  1.84053826  1.32863165]\n",
      " [-1.24020657  0.25604203 -0.69463841 -1.47833662]\n",
      " [-1.24020657 -0.56111338 -0.69463841 -0.54268053]\n",
      " [ 0.34844403 -0.23425122 -0.69463841 -0.54268053]\n",
      " [-1.24020657  1.56349069 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.47939784 -0.06084424 -0.54268053]\n",
      " [ 1.14276934 -0.88797555  0.57294993 -0.54268053]\n",
      " [ 1.14276934 -0.72454447 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203  1.20674409 -0.54268053]\n",
      " [ 1.14276934 -0.23425122  1.84053826  1.32863165]\n",
      " [-0.44588127 -0.47939784 -0.06084424 -1.47833662]\n",
      " [-0.44588127  1.23662853 -0.69463841 -2.41399271]\n",
      " [ 1.14276934  0.01089541  1.84053826 -0.54268053]\n",
      " [-0.44588127  2.21721502 -0.06084424 -2.41399271]\n",
      " [-1.24020657 -0.23425122 -0.69463841 -2.41399271]\n",
      " [-1.24020657 -0.96969109 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.47939784  0.57294993  1.32863165]\n",
      " [-0.44588127  0.74633528 -0.06084424  0.39297556]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  1.23662853  1.84053826 -0.54268053]\n",
      " [ 1.14276934 -0.23425122 -0.69463841  1.32863165]\n",
      " [-1.24020657  0.74633528  1.84053826 -0.54268053]\n",
      " [ 1.14276934 -0.47939784  0.57294993 -0.54268053]\n",
      " [ 1.14276934 -0.47939784  1.84053826 -0.54268053]\n",
      " [-0.44588127  0.25604203 -0.69463841 -0.54268053]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203  1.20674409 -0.54268053]\n",
      " [-0.44588127  0.25604203  1.84053826  0.39297556]\n",
      " [-1.24020657  1.23662853 -0.69463841 -0.54268053]\n",
      " [-1.24020657  0.01089541  1.84053826 -0.54268053]\n",
      " [ 1.14276934 -1.21483771 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  1.23662853  1.84053826  0.39297556]\n",
      " [ 1.14276934 -1.13312217  1.84053826  0.39297556]\n",
      " [-1.24020657 -0.88797555 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.47939784  1.84053826 -0.54268053]\n",
      " [-0.44588127 -1.21483771 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.01089541 -0.69463841  0.39297556]\n",
      " [ 0.34844403 -0.88797555 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203  1.84053826  1.32863165]\n",
      " [ 0.34844403 -0.72454447  1.20674409 -1.47833662]\n",
      " [-0.44588127  1.23662853  1.84053826 -1.47833662]\n",
      " [ 1.14276934  0.25604203 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -1.21483771 -0.69463841  1.32863165]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -0.54268053]\n",
      " [ 1.14276934  0.25604203  1.84053826 -0.54268053]\n",
      " [-0.44588127 -0.96969109 -0.69463841 -1.47833662]\n",
      " [-0.44588127  0.25604203 -0.06084424  0.39297556]\n",
      " [ 1.14276934  0.25604203  1.84053826 -0.54268053]\n",
      " [ 1.14276934  2.21721502  0.57294993  1.32863165]\n",
      " [ 1.14276934 -0.72454447 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.72454447 -0.69463841  1.32863165]\n",
      " [-0.44588127  0.25604203 -0.69463841  0.39297556]\n",
      " [-0.44588127 -0.23425122 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.23425122  1.84053826 -0.54268053]\n",
      " [-0.44588127  2.21721502 -0.69463841 -1.47833662]\n",
      " [-0.44588127 -0.72454447  0.57294993 -0.54268053]\n",
      " [ 1.14276934 -0.72454447  1.84053826  1.32863165]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [-1.24020657  1.23662853 -0.69463841  1.32863165]\n",
      " [-0.44588127 -0.47939784 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.96969109 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.47939784 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.47939784  1.20674409  0.39297556]\n",
      " [-1.24020657  1.23662853 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -1.21483771 -0.69463841 -0.54268053]\n",
      " [-0.44588127  1.23662853 -0.69463841  1.32863165]\n",
      " [ 1.14276934 -0.72454447 -0.69463841  1.32863165]\n",
      " [-0.44588127 -0.72454447 -0.69463841 -0.54268053]\n",
      " [-1.24020657  0.01089541 -0.69463841 -0.54268053]\n",
      " [-1.24020657 -0.72454447 -0.69463841  1.32863165]\n",
      " [ 0.34844403  0.74633528 -0.69463841  0.39297556]\n",
      " [ 1.14276934  2.21721502  1.84053826  1.32863165]\n",
      " [ 1.14276934 -0.47939784  1.84053826 -0.54268053]\n",
      " [-0.44588127 -0.88797555 -0.69463841 -1.47833662]\n",
      " [ 1.14276934  0.25604203  1.84053826 -0.54268053]\n",
      " [-0.44588127  1.23662853 -0.06084424  0.39297556]\n",
      " [ 1.14276934 -0.23425122 -0.69463841  1.32863165]\n",
      " [-0.44588127  0.25604203 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.72454447  1.20674409  1.32863165]\n",
      " [ 1.14276934  0.74633528  0.57294993 -0.54268053]\n",
      " [ 1.14276934 -0.72454447  1.84053826 -0.54268053]\n",
      " [-0.44588127  0.25604203 -0.69463841 -0.54268053]\n",
      " [ 1.14276934 -0.47939784 -0.06084424 -0.54268053]\n",
      " [-1.24020657  0.25604203 -0.69463841 -0.54268053]\n",
      " [-0.44588127 -0.72454447 -0.06084424 -0.54268053]\n",
      " [ 1.14276934 -0.72454447 -0.69463841  1.32863165]\n",
      " [ 1.14276934  3.19780152 -0.69463841  0.39297556]]\n"
     ]
    }
   ],
   "source": [
    "#predicted value must in this scale (range)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the logisctic regression model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build logit model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#predict = 1/0 , predict_log_proba = in logarithm, predict_proba = in probability\n",
    "#predict expect 2 dimentional arrays, row and column\n",
    "#pake feature scalling supaya sesuai\n",
    "print(classifier.predict(sc.transform([[1,18,1,4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32  51]\n",
      " [ 10 157]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.756"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show how many correct or incorrect prediction\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "#real result y_true, but since we want to distingush of real results in the training set\n",
    "#we called it y_true to true, y_train as training set, y_test as test set\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 32 correct prediction of class 0 => ga bisa bayar\n",
    "# 157 correct prediction of class 1 => bisa bayar\n",
    "# 51 incorrect prediction of class 1 => bisa bayar tapi kita mikir gak bisa\n",
    "# 10 incorrect prediction of class 0 => gak bisa bayar tapi kita pikir bisa\n",
    "# 75% correct prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
